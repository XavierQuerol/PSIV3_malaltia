{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc, recall_score, accuracy_score, precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import models\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from config import *\n",
    "import random\n",
    "import os\n",
    "\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Llegir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fhome/mapsiv01/psiv1/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/fhome/mapsiv01/psiv1/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model_autoencoder import Autoencoder\n",
    "model_autoencoder = Autoencoder()\n",
    "model_autoencoder.load_state_dict(torch.load(\"/fhome/mapsiv01/PSIV3_malaltia/autoencoder/models/model5_AUTOENCODER.pth\", map_location=torch.device('cpu')))\n",
    "\n",
    "\n",
    "from model_CNN_MlpClassifier import Classifier\n",
    "model_our = Classifier()\n",
    "model_our.load_state_dict(torch.load(\"/fhome/mapsiv01/PSIV3_malaltia/autoencoder/models/model_MLPour_classifier.pth\", map_location=torch.device('cpu')))\n",
    "\n",
    "\n",
    "model_resnet = models.resnet50(pretrained=True)\n",
    "for param in model_resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "num_ftrs = model_resnet.fc.in_features\n",
    "model_resnet.fc = nn.Sequential(\n",
    "nn.Linear(num_ftrs, 128),  # Replace the last fully connected layer with your custom layers\n",
    "nn.ReLU(),\n",
    "nn.Dropout(0.5),\n",
    "nn.Linear(128, 2)  # Assuming your final output has 2 classes, modify this as needed\n",
    "    )\n",
    "model_resnet.load_state_dict(torch.load(\"/fhome/mapsiv01/PSIV3_malaltia/autoencoder/models/model_MLPresnet.pth\", map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128), antialias=True),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Adjust mean and std as needed\n",
    "])\n",
    "\n",
    "def read_img(file, dir):\n",
    "    img = read_image(os.path.join(dir, file))[:-1,:,:]\n",
    "    img = img.to(torch.float32)\n",
    "    img = img/255\n",
    "    img = transform(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funció per calcular mètriques per un Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_crossval(pred, target):\n",
    "       \n",
    "    combined = list(zip(pred, target))\n",
    "\n",
    "    random.shuffle(combined)\n",
    "\n",
    "    pred, target = zip(*combined)\n",
    "\n",
    "    interval = int(len(pred)/10)\n",
    "\n",
    "    kfolds = [(pred[:interval*i]+pred[interval*i+1:], target[:interval*i]+target[interval*i+1:],\n",
    "               pred[interval*i:interval*(i+1)], target[interval*i:interval*(i+1)]) for i in range(10)]\n",
    "    \n",
    "    return kfolds\n",
    "\n",
    "def calculate_mean_error(data):\n",
    "    mean = np.mean(data)\n",
    "    std_dev = np.std(data, ddof=1)  # ddof=1 for sample standard deviation\n",
    "    sample_size = len(data)\n",
    "\n",
    "    # Calculate the t-distribution critical value\n",
    "    t_critical = 2.262\n",
    "\n",
    "    # Calculate the margin of error\n",
    "    margin_of_error = t_critical * (std_dev / np.sqrt(sample_size))\n",
    "\n",
    "    return f\"{mean} +/- {margin_of_error}\"\n",
    "\n",
    "       \n",
    "\n",
    "def calculate_metrics(pred, target):\n",
    "\n",
    "    recalls, precisions, f1_scores = [], [], []\n",
    "\n",
    "    kfolds = create_crossval(pred, target)\n",
    "\n",
    "    for (pred_train, target_train, pred_test, target_test) in kfolds:\n",
    "        df = pd.DataFrame({\"Target\": target_train, \"Predicted\": pred_train})\n",
    "        fpr, tpr, thresholds = roc_curve(df['Target'], df['Predicted'])\n",
    "\n",
    "        J2 = tpr - fpr  \n",
    "        best_threshold = thresholds[np.argmax(J2)]\n",
    "\n",
    "        pred_test = [0 if prob < best_threshold else 1 for prob in pred_test]\n",
    "\n",
    "\n",
    "        recall = recall_score(pred_test, target_test)\n",
    "        precision = precision_score(pred_test, target_test)\n",
    "        f1_score = (2*recall*precision)/(recall+precision)\n",
    "\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        f1_scores.append(f1_score)\n",
    "    \n",
    "    recall = calculate_mean_error(recalls)\n",
    "    precision = calculate_mean_error(precisions)\n",
    "    f1_score = calculate_mean_error(f1_scores)\n",
    "\n",
    "\n",
    "    return recall, precision, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories_cr = [dir.path for dir in os.scandir(CROPPED_PATCHES_DIR) if dir.is_dir()]\n",
    "metadata = pd.read_csv(METADATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula(model, method, amb_baixa):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "    model_name = model[0]\n",
    "    model = model[1]\n",
    "    model = model.to(device)\n",
    "\n",
    "    preds = []\n",
    "    targets = []\n",
    "\n",
    "    for dir in directories_cr:\n",
    "        if metadata.loc[metadata[\"CODI\"] == dir.split(\"/\")[-1].split(\"_\")[0], \"DENSITAT\"].values[0] == \"NEGATIVA\":\n",
    "            target = 0\n",
    "        elif metadata.loc[metadata[\"CODI\"] == dir.split(\"/\")[-1].split(\"_\")[0], \"DENSITAT\"].values[0] == \"ALTA\":\n",
    "            target = 1\n",
    "        else:\n",
    "            if amb_baixa:\n",
    "                target = 1\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        files = os.listdir(dir)\n",
    "        random.shuffle(files)\n",
    "\n",
    "        pred_patches = []\n",
    "        imgs = []\n",
    "        for file in files[:30]:\n",
    "            img = read_img(file, dir)\n",
    "            imgs.append(img)\n",
    "\n",
    "        stacked_imgs = torch.stack(imgs)  # This creates a tensor of shape (num_images, channels, height, width)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(stacked_imgs.to(device))\n",
    "            output = torch.sigmoid(output)\n",
    "            pred_patches = []\n",
    "        for i in range(output.shape[0]):\n",
    "            output2 = output[i, :]\n",
    "            if method == \"prob\":\n",
    "                output2 = output2[torch.argmax(output2).item()].item()\n",
    "            elif method == \"discrete\":\n",
    "                output2 = torch.argmax(output2).item()\n",
    "            pred_patches.append(output2)\n",
    "        \n",
    "        preds.append(sum(pred_patches)/len(files))\n",
    "        targets.append(target)\n",
    "\n",
    "\n",
    "    recall, precision, f1_score = calculate_metrics(preds, targets)\n",
    "\n",
    "    print(f\"Model: {model_name}, Method: {method}, Baixa: {amb_baixa}\")\n",
    "    print(f\"Recall: {recall}, Precision: {precision}, F1_score: {f1_score}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: our, Method: prob, Baixa: True\n",
      "Recall: 0.5945879404393336 +/- 0.07437233374631352, Precision: 0.8354842543077836 +/- 0.0760207240227953, F1_score: 0.6876792027488936 +/- 0.05774363794425387\n",
      "\n",
      "Model: our, Method: prob, Baixa: False\n",
      "Recall: 0.4568075062192709 +/- 0.06727175239187745, Precision: 0.8341666666666667 +/- 0.12630750352699643, F1_score: 0.5840383300909616 +/- 0.07849851902487531\n",
      "\n",
      "Model: our, Method: discrete, Baixa: True\n",
      "Recall: 0.8376587301587302 +/- 0.0761013512487516, Precision: 0.5881135531135532 +/- 0.08672852508411119, F1_score: 0.679334576559977 +/- 0.050113495128605405\n",
      "\n",
      "Model: our, Method: discrete, Baixa: False\n",
      "Recall: 0.6628787878787878 +/- 0.15204503598257374, Precision: 0.7415873015873016 +/- 0.17329420097949527, F1_score: 0.661169892199304 +/- 0.13133755594840218\n",
      "\n",
      "Model: resnet, Method: prob, Baixa: True\n",
      "Recall: 0.6056383322559793 +/- 0.07084948477679817, Precision: 0.7949938949938951 +/- 0.08076336415834749, F1_score: 0.6830546051311771 +/- 0.0663969816727901\n",
      "\n",
      "Model: resnet, Method: prob, Baixa: False\n",
      "Recall: 0.4682359307359308 +/- 0.06204077476265224, Precision: 0.846031746031746 +/- 0.11210898970449408, F1_score: 0.6010755454667824 +/- 0.0757796202976338\n",
      "\n",
      "Model: resnet, Method: discrete, Baixa: True\n",
      "Recall: 0.9221911421911422 +/- 0.05987423986224565, Precision: 0.8561471861471862 +/- 0.0844483211453507, F1_score: 0.8840156740441371 +/- 0.061021747936316637\n",
      "\n",
      "Model: resnet, Method: discrete, Baixa: False\n",
      "Recall: 0.9205555555555556 +/- 0.06628643688428887, Precision: 0.9584415584415584 +/- 0.06638510258459965, F1_score: 0.932905175320036 +/- 0.04060283509958427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [[\"our\", model_our], [\"resnet\", model_resnet]]\n",
    "methods = [\"prob\", \"discrete\"]\n",
    "amb_baixa = [True, False]\n",
    "\n",
    "for (model, method, amb_baixa) in product(models, methods, amb_baixa):\n",
    "    calcula(model, method, amb_baixa)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psiv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
